from pickletools import genops, opcodes, OpcodeInfo
import zipfile
import io
import os
from os.path import join
import subprocess
import tarfile
from tqdm import tqdm
from exceptions import *

class PickleEC():
    def __init__(self):
        pass

    @staticmethod
    def _is_zipfile(f) -> bool:
        # This is a stricter implementation than zipfile.is_zipfile().
        # zipfile.is_zipfile() is True if the magic number appears anywhere in the
        # binary. Since we expect the files here to be generated by torch.save or
        # torch.jit.save, it's safe to only check the start bytes and avoid
        # collisions and assume the zip has only 1 file.
        # See bugs.python.org/issue28494.

        # Read the first 4 bytes of the file
        read_bytes = []
        start = f.tell()

        byte = f.read(1)
        while byte != "":
            read_bytes.append(byte)
            if len(read_bytes) == 4:
                break
            byte = f.read(1)
        f.seek(start)

        local_header_magic_number = [b'P', b'K', b'\x03', b'\x04']
        return read_bytes == local_header_magic_number

    @staticmethod
    def _is_tarfile(f):
        try:
            with tarfile.open(fileobj=f, mode='r:', format=tarfile.PAX_FORMAT) as tar:
                tarfile.list()
            return True
        except tarfile.TarError:
            return False

    @staticmethod
    def _extract_zip(dir_name, bin_name):
        with zipfile.ZipFile(join(dir_name, bin_name), 'r') as zip_ref:
            zip_ref.extractall(dir_name)
        return

    @staticmethod
    def _extract_tar(dir_name, bin_name):
        pass

    @staticmethod
    def _extract_pickle(dir_name, bin_name):
        path_to_bin = os.path.join(dir_name, bin_name)
        places_to_start = [0]
        start_pos = 0
        while True:
            with open(path_to_bin, 'rb') as f:
                f.seek(start_pos)
                try:
                    temp_data = list(genops(f))
                    start_pos = temp_data[-1][2] + 1
                    places_to_start.append(start_pos)
                except Exception as e:
                    print("Hit end of pickle files in bin file,", e)
                    f.close()
                    break

        with open(path_to_bin, 'rb') as f:
            file_data = bytearray(f.read())
            f.close()

        for i in tqdm(range(len(places_to_start))):
            if not os.path.isdir(os.path.join(dir_name, 'pickle_files')):
                os.mkdir(os.path.join(dir_name, 'pickle_files'))
            new_pkl_file = os.path.join(dir_name, 'pickle_files', 'file_' + str(i) + '.pickle')
            with open(new_pkl_file, 'wb') as new_f:
                if i != len(places_to_start) - 1:
                    new_f.write(file_data[places_to_start[i]:places_to_start[i + 1]])
                else:
                    new_f.write(file_data[places_to_start[i]:])
                new_f.close()
        return

    def extract(self, dir_name, bin_name):
        path_to_bin = os.path.join(dir_name, bin_name)
        file_obj = self.read_pickle(path_to_bin)
        if self._is_zipfile(file_obj):
            self._extract_zip(dir_name, bin_name)
        elif self._is_tarfile(file_obj):
            self._extract_tar(dir_name, bin_name)
        else:
            self._extract_pickle(dir_name, bin_name)
        return

    @staticmethod
    def _compress_zip(working_dir, bin_name, source_dir):
        print('cd ' + working_dir + '; zip -r ' + bin_name + ' ' + source_dir + '/')
        subprocess.run('cd ' + working_dir + '; zip -r ' + bin_name + ' ' + source_dir + '/', shell=True,
                       capture_output=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return

    @staticmethod
    def _compress_tar(working_dir, bin_name, source_dir):
        pass

    @staticmethod
    def _compress_pickle(working_dir, bin_name, source_dir):
        path_to_new_bin = os.path.join(working_dir, bin_name)
        path_to_pickle_files = os.path.join(working_dir, source_dir)
        list_of_pickle_files=[os.listdir(path_to_pickle_files)]

        with open(path_to_new_bin, 'ab') as new_b:
            for i in range(len(list_of_pickle_files)):
                with open(os.path.join(path_to_pickle_files, 'file_'+str(i)+'.pickle'), 'rb') as f:
                    temp_data = bytearray(f.read())
                    f.close()
                new_b.write(temp_data)
            new_b.close()
        return

    def compress(self, working_dir, bin_name):

        if os.path.isdir(os.path.join(working_dir, 'archive')):
            self._compress_zip(working_dir, bin_name, 'archive')
        elif os.path.isdir(os.path.join(working_dir, 'pickle_files')):
            self._compress_pickle(working_dir, bin_name, 'pickle_files')
        else:# for tar files
            pass
        return

    @staticmethod
    def read_pickle_to_bytearray(path_to_pickle_file):
        with open(path_to_pickle_file, 'rb') as f:
            data = io.BytesIO(f.read())
            f.close()
        data_bytearray = bytearray(data.read())
        return data_bytearray

    @staticmethod
    def read_pickle_from_file_obj_to_bytearray(file_obj):
        current_pointer = file_obj.tell()
        file_obj.seek(0)
        data = io.BytesIO(file_obj.read())
        data_bytearray = bytearray(data.read())
        file_obj.seek(current_pointer)
        return data_bytearray

    @staticmethod
    def read_pickle(path_to_pickle_file):
        f = open(path_to_pickle_file, 'rb')
        return f

    @staticmethod
    def close_fileobj(file_obj):
        file_obj.close()

    @staticmethod
    def write_pickle_from_bytearray(data_bytearray, path_to_pickle_file):
        if os.path.isfile(path_to_pickle_file):
            os.remove(path_to_pickle_file)
        with open(path_to_pickle_file, 'wb') as f:
            f.write(data_bytearray)
            f.close()
